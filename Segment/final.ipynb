{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-61adcb3df0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#ignore warning messages \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"A_Z Handwritten Data.csv\").astype('float32')\n",
    "dataset.rename(columns={'0':'label'}, inplace=True)\n",
    "\n",
    "# Splite data the X - Our data , and y - the prdict label\n",
    "X = dataset.drop('label',axis = 1)\n",
    "y = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of each labels\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Amount of each labels\")\n",
    "\n",
    "# Change label to alphabets\n",
    "alphabets_mapper = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'} \n",
    "dataset_alphabets = dataset.copy()\n",
    "dataset['label'] = dataset['label'].map(alphabets_mapper)\n",
    "\n",
    "label_size = dataset.groupby('label').size()\n",
    "label_size.plot.barh(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splite the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# scale data\n",
    "standard_scaler = MinMaxScaler()\n",
    "standard_scaler.fit(X_train)\n",
    "\n",
    "X_train = standard_scaler.transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1092/1092 [==============================] - 156s 141ms/step - loss: 0.5139 - accuracy: 0.8566 - val_loss: 0.0949 - val_accuracy: 0.9747\n",
      "Epoch 2/20\n",
      "1092/1092 [==============================] - 137s 125ms/step - loss: 0.0984 - accuracy: 0.9732 - val_loss: 0.0700 - val_accuracy: 0.9804\n",
      "Epoch 3/20\n",
      "1092/1092 [==============================] - 129s 118ms/step - loss: 0.0716 - accuracy: 0.9797 - val_loss: 0.0579 - val_accuracy: 0.9837\n",
      "Epoch 4/20\n",
      "1092/1092 [==============================] - 129s 118ms/step - loss: 0.0559 - accuracy: 0.9842 - val_loss: 0.0496 - val_accuracy: 0.9861\n",
      "Epoch 5/20\n",
      "1092/1092 [==============================] - 160s 146ms/step - loss: 0.0469 - accuracy: 0.9862 - val_loss: 0.0476 - val_accuracy: 0.9867\n",
      "Epoch 6/20\n",
      "1092/1092 [==============================] - 144s 132ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.0456 - val_accuracy: 0.9866\n",
      "Epoch 7/20\n",
      "1092/1092 [==============================] - 177s 162ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0390 - val_accuracy: 0.9891\n",
      "Epoch 8/20\n",
      "1092/1092 [==============================] - 131s 120ms/step - loss: 0.0294 - accuracy: 0.9910 - val_loss: 0.0363 - val_accuracy: 0.9896\n",
      "Epoch 9/20\n",
      "1092/1092 [==============================] - 116s 106ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.0358 - val_accuracy: 0.9901\n",
      "Epoch 10/20\n",
      "1092/1092 [==============================] - 131s 120ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0357 - val_accuracy: 0.9897\n",
      "Epoch 11/20\n",
      "1092/1092 [==============================] - 111s 102ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0325 - val_accuracy: 0.9911\n",
      "Epoch 12/20\n",
      "1092/1092 [==============================] - 113s 103ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0324 - val_accuracy: 0.9912\n",
      "Epoch 13/20\n",
      "1092/1092 [==============================] - 113s 103ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.0300 - val_accuracy: 0.9925\n",
      "Epoch 14/20\n",
      "1092/1092 [==============================] - 113s 103ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0313 - val_accuracy: 0.9923\n",
      "Epoch 15/20\n",
      "1092/1092 [==============================] - 113s 104ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0284 - val_accuracy: 0.9932\n",
      "Epoch 16/20\n",
      "1092/1092 [==============================] - 112s 102ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0279 - val_accuracy: 0.9936\n",
      "Epoch 17/20\n",
      "1092/1092 [==============================] - 112s 102ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0305 - val_accuracy: 0.9932\n",
      "Epoch 18/20\n",
      "1092/1092 [==============================] - 112s 103ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0292 - val_accuracy: 0.9932\n",
      "Epoch 19/20\n",
      "1092/1092 [==============================] - 115s 105ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0294 - val_accuracy: 0.9937\n",
      "Epoch 20/20\n",
      "1092/1092 [==============================] - 116s 106ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0275 - val_accuracy: 0.9943\n"
     ]
    }
   ],
   "source": [
    "cls = Sequential()\n",
    "cls.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "cls.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cls.add(Dropout(0.3))\n",
    "cls.add(Flatten())\n",
    "cls.add(Dense(128, activation='relu'))\n",
    "cls.add(Dense(len(y.unique()), activation='softmax'))\n",
    "\n",
    "cls.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = cls.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageEnhance, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('n_image copy.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACEAAAAoCAAAAABVgMx7AAACTElEQVR4nHWTy3LjNhBFDx96kLQzcpJJVaqySOX/v2syZc/IkvkmCJwsHEn2QnfXwMHtbqCBFyWTZ+dLOJmis5OZvGuhzEl5LLjp+Q8Ab1rCzcL0Lar25hf+dSaVeD2f/bnS8qMmu60x7vJbcN7t51QRNre16Vjlcxov4Zf9ajWRbnXA3/+uH4ryxcDDSa9EBUaXKzD7yhMussTJ4GqE2sV4RcJwAN/EYK/ftYHWcE3Ua8HhPUswaqCqqcfuahH1/bbKZCxDqmKR97gnXZrLQ/eQDVnX4Ggb1YLfMnC4eJw14wvKNJtcpgZWD9Uti/bTlvIkeu57IxUmnrh6jIPtL1uUtde1q/LCpB8fMq1SsZgXM7TNPkWyOHPIFhg4h+X/l0ow6aDUjydVfi06Q7BzNn77B5TO1pW/0DaufgX1fHSJDtKg2BuEPI7q8/yYsai2g06QKyE69tsMXV6S7YbN9mgY9Pgi7GbRk7tmY3dOLroUbDTOaU66NgT5oSkjC446dioPpEH159STKXo220ftPOuslOjkq6uym2SOlp8mPlGjxhS0RvPtshZU6TqucXV4zFbyrkxpepzAIL837W38wvtcRF+nHIyMAvZXoHNeGtBO+coiuikPwwdEF6lIYyc5is8ULL5dtk+r0Td2aKzBiMtTju0Hi9agbCFR00tM3cOk0+2fOHjszdjUsPfTv/2kdVOu9YDkdwBy12KA+T4x87JK2FHeIwoOfZKU362Dti5iirvsbhaKoi82ZPfrGOrvTdfvw/1uOR0wIxb/AetB2NNoPMSRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=33x40 at 0x7FBE6FF1B490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lol_img = cv2.imread('n_image copy.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "my_lol_img = cv2.resize(my_lol_img, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbc020b4730>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(my_lol_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, 255, 255, 255, 255, 253, 254, 254, 255, 244, 254,\n",
       "        252, 255, 255, 255, 255, 255, 255, 251, 254, 254, 253, 250, 253,\n",
       "        251, 254],\n",
       "       [255, 255, 255, 255, 255, 255, 254, 253, 253, 252, 252, 254, 252,\n",
       "        254, 255, 255, 255, 255, 255, 255, 255, 241, 254, 253, 250, 255,\n",
       "        250, 254],\n",
       "       [255, 255, 255, 255, 255, 255, 252, 242, 252, 250, 254, 254, 250,\n",
       "        255, 255, 255, 255, 255, 255, 255, 254, 254, 249, 252, 247, 245,\n",
       "        250, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 254, 248, 249, 254, 252, 253,\n",
       "        252, 255, 255, 255, 255, 255, 255, 250, 250, 253, 248, 251, 253,\n",
       "        250, 254],\n",
       "       [255, 255, 255, 255, 255, 255, 217,  18,  32, 176, 250, 254, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 239, 254, 205,  22, 146,\n",
       "        251, 255],\n",
       "       [253, 254, 253, 254, 254, 254, 229,  63,   0, 116, 243, 253, 252,\n",
       "        254, 255, 255, 255, 255, 255, 255, 252, 253, 237,   7,   7, 141,\n",
       "        249, 254],\n",
       "       [254, 252, 251, 251, 255, 237, 255, 171,   4,   1, 215, 254, 252,\n",
       "        253, 255, 255, 255, 255, 255, 255, 250, 253, 249,   5,   5, 140,\n",
       "        250, 255],\n",
       "       [254, 253, 252, 253, 253, 255, 210,   3,   8,   2,   8, 248, 248,\n",
       "        255, 255, 255, 255, 255, 255, 255, 254, 254, 247,   3,   2, 111,\n",
       "        239, 255],\n",
       "       [254, 250, 250, 250, 251, 255, 212,   3,   8,   4,   3, 100, 253,\n",
       "        251, 255, 255, 255, 255, 255, 255, 249, 252, 244,   5,   7,   5,\n",
       "        184, 254],\n",
       "       [248, 250, 254, 254, 251, 248,   9,   0, 130, 254,  45,  21, 233,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 254, 246, 200,   4,   2,\n",
       "        177, 254],\n",
       "       [253, 249, 249, 249, 249, 133,   2,  47, 193, 254, 143,   8,  58,\n",
       "        252, 255, 255, 255, 255, 255, 255, 252, 250, 253, 201,   7,   3,\n",
       "        185, 255],\n",
       "       [253, 243, 255, 246, 251,  21,   0,  87, 255, 253, 249,   1,  15,\n",
       "        113, 253, 255, 246, 253, 244, 250, 253, 254, 252, 205,   0,   4,\n",
       "        183, 254],\n",
       "       [247, 254, 250, 252, 181,  13,  21, 149, 248, 253, 254, 242,   8,\n",
       "          8, 147, 253, 253, 247, 249, 250, 251, 254, 250, 196,  15,   2,\n",
       "        187, 255],\n",
       "       [252, 248, 252, 253,  50,   6,  42, 252, 251, 254, 254, 236, 156,\n",
       "          6,  32, 205, 255, 252, 252, 250, 246, 254, 253, 200,   1,   2,\n",
       "        187, 255],\n",
       "       [252, 253, 250, 214,  44,   2,  86, 252, 251, 243, 251, 254, 202,\n",
       "         34,   3,   5, 229, 254, 250, 250, 254, 243, 239, 216,  35,   4,\n",
       "        184, 254],\n",
       "       [244, 253, 252,  97,   4,   2, 252, 249, 250, 255, 249, 248, 254,\n",
       "        217,  68,   7,  86, 253, 250, 253, 253, 254, 244, 250, 156,   2,\n",
       "        186, 255],\n",
       "       [255, 251, 240,  89,   6, 249, 255, 251, 250, 246, 253, 255, 251,\n",
       "        255, 115,   7,   1, 239, 253, 251, 245, 252, 252, 255, 160,   4,\n",
       "        184, 254],\n",
       "       [252, 251, 142,   2,   4, 249, 255, 255, 255, 255, 255, 255, 255,\n",
       "        254, 252, 156,  11,  21, 166, 254, 254, 249, 253, 254, 161,   6,\n",
       "        185, 255],\n",
       "       [254, 252, 141,  12,  12, 239, 251, 255, 255, 255, 255, 255, 255,\n",
       "        255, 252, 254,  13,   1,  77, 255, 254, 254, 240, 203,  12,   1,\n",
       "        186, 253],\n",
       "       [250, 187,   2,   4, 203, 248, 252, 255, 255, 255, 255, 255, 255,\n",
       "        252, 252, 252, 250,  86,   1,  81, 224, 247, 251, 205,   5,   6,\n",
       "        184, 255],\n",
       "       [253, 175,   2,   3, 201, 255, 245, 255, 255, 255, 255, 255, 255,\n",
       "        250, 249, 254, 252, 247, 133,   3,  38, 221, 253, 205,   5,   0,\n",
       "        187, 253],\n",
       "       [254, 201,  38,  35, 215, 246, 254, 255, 255, 255, 255, 255, 255,\n",
       "        254, 254, 248, 253, 252, 252, 157,  22,   1,   5, 162,   3,   4,\n",
       "        181, 204],\n",
       "       [254, 253, 214, 221, 254, 255, 253, 255, 255, 255, 255, 255, 255,\n",
       "        254, 254, 255, 252, 254, 249, 253, 193,  26,   4,   4,   4,   2,\n",
       "        187, 172],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 253, 255,  17,  20,  11,  10,\n",
       "        187, 254],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 250, 254, 243, 249, 203, 197,\n",
       "        254, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 245, 252, 254, 251, 249,\n",
       "        252, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 252, 249, 246, 248, 251, 250,\n",
       "        252, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 253, 244, 250, 254, 252, 254,\n",
       "        252, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lol_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lol_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lol_img = np.array(my_lol_img) / 255\n",
    "my_lol_img = my_lol_img.reshape(-1, 28, 28, 1)\n",
    "#y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99215686],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [0.95686275],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98431373],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99215686],\n",
       "         [0.98039216],\n",
       "         [0.99215686],\n",
       "         [0.98431373],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.99215686],\n",
       "         [0.99215686],\n",
       "         [0.98823529],\n",
       "         [0.98823529],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.94509804],\n",
       "         [0.99607843],\n",
       "         [0.99215686],\n",
       "         [0.98039216],\n",
       "         [1.        ],\n",
       "         [0.98039216],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.94901961],\n",
       "         [0.98823529],\n",
       "         [0.98039216],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.98039216],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.97647059],\n",
       "         [0.98823529],\n",
       "         [0.96862745],\n",
       "         [0.96078431],\n",
       "         [0.98039216],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.97254902],\n",
       "         [0.97647059],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.99215686],\n",
       "         [0.98823529],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98039216],\n",
       "         [0.98039216],\n",
       "         [0.99215686],\n",
       "         [0.97254902],\n",
       "         [0.98431373],\n",
       "         [0.99215686],\n",
       "         [0.98039216],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.85098039],\n",
       "         [0.07058824],\n",
       "         [0.1254902 ],\n",
       "         [0.69019608],\n",
       "         [0.98039216],\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.9372549 ],\n",
       "         [0.99607843],\n",
       "         [0.80392157],\n",
       "         [0.08627451],\n",
       "         [0.57254902],\n",
       "         [0.98431373],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99215686],\n",
       "         [0.99607843],\n",
       "         [0.99215686],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.89803922],\n",
       "         [0.24705882],\n",
       "         [0.        ],\n",
       "         [0.45490196],\n",
       "         [0.95294118],\n",
       "         [0.99215686],\n",
       "         [0.98823529],\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.99215686],\n",
       "         [0.92941176],\n",
       "         [0.02745098],\n",
       "         [0.02745098],\n",
       "         [0.55294118],\n",
       "         [0.97647059],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.98431373],\n",
       "         [0.98431373],\n",
       "         [1.        ],\n",
       "         [0.92941176],\n",
       "         [1.        ],\n",
       "         [0.67058824],\n",
       "         [0.01568627],\n",
       "         [0.00392157],\n",
       "         [0.84313725],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98039216],\n",
       "         [0.99215686],\n",
       "         [0.97647059],\n",
       "         [0.01960784],\n",
       "         [0.01960784],\n",
       "         [0.54901961],\n",
       "         [0.98039216],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [0.99215686],\n",
       "         [0.98823529],\n",
       "         [0.99215686],\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [0.82352941],\n",
       "         [0.01176471],\n",
       "         [0.03137255],\n",
       "         [0.00784314],\n",
       "         [0.03137255],\n",
       "         [0.97254902],\n",
       "         [0.97254902],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.96862745],\n",
       "         [0.01176471],\n",
       "         [0.00784314],\n",
       "         [0.43529412],\n",
       "         [0.9372549 ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [0.98039216],\n",
       "         [0.98039216],\n",
       "         [0.98039216],\n",
       "         [0.98431373],\n",
       "         [1.        ],\n",
       "         [0.83137255],\n",
       "         [0.01176471],\n",
       "         [0.03137255],\n",
       "         [0.01568627],\n",
       "         [0.01176471],\n",
       "         [0.39215686],\n",
       "         [0.99215686],\n",
       "         [0.98431373],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.97647059],\n",
       "         [0.98823529],\n",
       "         [0.95686275],\n",
       "         [0.01960784],\n",
       "         [0.02745098],\n",
       "         [0.01960784],\n",
       "         [0.72156863],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.97254902],\n",
       "         [0.98039216],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.98431373],\n",
       "         [0.97254902],\n",
       "         [0.03529412],\n",
       "         [0.        ],\n",
       "         [0.50980392],\n",
       "         [0.99607843],\n",
       "         [0.17647059],\n",
       "         [0.08235294],\n",
       "         [0.91372549],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.96470588],\n",
       "         [0.78431373],\n",
       "         [0.01568627],\n",
       "         [0.00784314],\n",
       "         [0.69411765],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.99215686],\n",
       "         [0.97647059],\n",
       "         [0.97647059],\n",
       "         [0.97647059],\n",
       "         [0.97647059],\n",
       "         [0.52156863],\n",
       "         [0.00784314],\n",
       "         [0.18431373],\n",
       "         [0.75686275],\n",
       "         [0.99607843],\n",
       "         [0.56078431],\n",
       "         [0.03137255],\n",
       "         [0.22745098],\n",
       "         [0.98823529],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.98039216],\n",
       "         [0.99215686],\n",
       "         [0.78823529],\n",
       "         [0.02745098],\n",
       "         [0.01176471],\n",
       "         [0.7254902 ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99215686],\n",
       "         [0.95294118],\n",
       "         [1.        ],\n",
       "         [0.96470588],\n",
       "         [0.98431373],\n",
       "         [0.08235294],\n",
       "         [0.        ],\n",
       "         [0.34117647],\n",
       "         [1.        ],\n",
       "         [0.99215686],\n",
       "         [0.97647059],\n",
       "         [0.00392157],\n",
       "         [0.05882353],\n",
       "         [0.44313725],\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [0.96470588],\n",
       "         [0.99215686],\n",
       "         [0.95686275],\n",
       "         [0.98039216],\n",
       "         [0.99215686],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.80392157],\n",
       "         [0.        ],\n",
       "         [0.01568627],\n",
       "         [0.71764706],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.96862745],\n",
       "         [0.99607843],\n",
       "         [0.98039216],\n",
       "         [0.98823529],\n",
       "         [0.70980392],\n",
       "         [0.05098039],\n",
       "         [0.08235294],\n",
       "         [0.58431373],\n",
       "         [0.97254902],\n",
       "         [0.99215686],\n",
       "         [0.99607843],\n",
       "         [0.94901961],\n",
       "         [0.03137255],\n",
       "         [0.03137255],\n",
       "         [0.57647059],\n",
       "         [0.99215686],\n",
       "         [0.99215686],\n",
       "         [0.96862745],\n",
       "         [0.97647059],\n",
       "         [0.98039216],\n",
       "         [0.98431373],\n",
       "         [0.99607843],\n",
       "         [0.98039216],\n",
       "         [0.76862745],\n",
       "         [0.05882353],\n",
       "         [0.00784314],\n",
       "         [0.73333333],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.98823529],\n",
       "         [0.97254902],\n",
       "         [0.98823529],\n",
       "         [0.99215686],\n",
       "         [0.19607843],\n",
       "         [0.02352941],\n",
       "         [0.16470588],\n",
       "         [0.98823529],\n",
       "         [0.98431373],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.9254902 ],\n",
       "         [0.61176471],\n",
       "         [0.02352941],\n",
       "         [0.1254902 ],\n",
       "         [0.80392157],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.98823529],\n",
       "         [0.98039216],\n",
       "         [0.96470588],\n",
       "         [0.99607843],\n",
       "         [0.99215686],\n",
       "         [0.78431373],\n",
       "         [0.00392157],\n",
       "         [0.00784314],\n",
       "         [0.73333333],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.98823529],\n",
       "         [0.99215686],\n",
       "         [0.98039216],\n",
       "         [0.83921569],\n",
       "         [0.17254902],\n",
       "         [0.00784314],\n",
       "         [0.3372549 ],\n",
       "         [0.98823529],\n",
       "         [0.98431373],\n",
       "         [0.95294118],\n",
       "         [0.98431373],\n",
       "         [0.99607843],\n",
       "         [0.79215686],\n",
       "         [0.13333333],\n",
       "         [0.01176471],\n",
       "         [0.01960784],\n",
       "         [0.89803922],\n",
       "         [0.99607843],\n",
       "         [0.98039216],\n",
       "         [0.98039216],\n",
       "         [0.99607843],\n",
       "         [0.95294118],\n",
       "         [0.9372549 ],\n",
       "         [0.84705882],\n",
       "         [0.1372549 ],\n",
       "         [0.01568627],\n",
       "         [0.72156863],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.95686275],\n",
       "         [0.99215686],\n",
       "         [0.98823529],\n",
       "         [0.38039216],\n",
       "         [0.01568627],\n",
       "         [0.00784314],\n",
       "         [0.98823529],\n",
       "         [0.97647059],\n",
       "         [0.98039216],\n",
       "         [1.        ],\n",
       "         [0.97647059],\n",
       "         [0.97254902],\n",
       "         [0.99607843],\n",
       "         [0.85098039],\n",
       "         [0.26666667],\n",
       "         [0.02745098],\n",
       "         [0.3372549 ],\n",
       "         [0.99215686],\n",
       "         [0.98039216],\n",
       "         [0.99215686],\n",
       "         [0.99215686],\n",
       "         [0.99607843],\n",
       "         [0.95686275],\n",
       "         [0.98039216],\n",
       "         [0.61176471],\n",
       "         [0.00784314],\n",
       "         [0.72941176],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [0.98431373],\n",
       "         [0.94117647],\n",
       "         [0.34901961],\n",
       "         [0.02352941],\n",
       "         [0.97647059],\n",
       "         [1.        ],\n",
       "         [0.98431373],\n",
       "         [0.98039216],\n",
       "         [0.96470588],\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [0.98431373],\n",
       "         [1.        ],\n",
       "         [0.45098039],\n",
       "         [0.02745098],\n",
       "         [0.00392157],\n",
       "         [0.9372549 ],\n",
       "         [0.99215686],\n",
       "         [0.98431373],\n",
       "         [0.96078431],\n",
       "         [0.98823529],\n",
       "         [0.98823529],\n",
       "         [1.        ],\n",
       "         [0.62745098],\n",
       "         [0.01568627],\n",
       "         [0.72156863],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.98823529],\n",
       "         [0.98431373],\n",
       "         [0.55686275],\n",
       "         [0.00784314],\n",
       "         [0.01568627],\n",
       "         [0.97647059],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.61176471],\n",
       "         [0.04313725],\n",
       "         [0.08235294],\n",
       "         [0.65098039],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.97647059],\n",
       "         [0.99215686],\n",
       "         [0.99607843],\n",
       "         [0.63137255],\n",
       "         [0.02352941],\n",
       "         [0.7254902 ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.55294118],\n",
       "         [0.04705882],\n",
       "         [0.04705882],\n",
       "         [0.9372549 ],\n",
       "         [0.98431373],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.99607843],\n",
       "         [0.05098039],\n",
       "         [0.00392157],\n",
       "         [0.30196078],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.94117647],\n",
       "         [0.79607843],\n",
       "         [0.04705882],\n",
       "         [0.00392157],\n",
       "         [0.72941176],\n",
       "         [0.99215686]],\n",
       "\n",
       "        [[0.98039216],\n",
       "         [0.73333333],\n",
       "         [0.00784314],\n",
       "         [0.01568627],\n",
       "         [0.79607843],\n",
       "         [0.97254902],\n",
       "         [0.98823529],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.98823529],\n",
       "         [0.98823529],\n",
       "         [0.98039216],\n",
       "         [0.3372549 ],\n",
       "         [0.00392157],\n",
       "         [0.31764706],\n",
       "         [0.87843137],\n",
       "         [0.96862745],\n",
       "         [0.98431373],\n",
       "         [0.80392157],\n",
       "         [0.01960784],\n",
       "         [0.02352941],\n",
       "         [0.72156863],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.99215686],\n",
       "         [0.68627451],\n",
       "         [0.00784314],\n",
       "         [0.01176471],\n",
       "         [0.78823529],\n",
       "         [1.        ],\n",
       "         [0.96078431],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98039216],\n",
       "         [0.97647059],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.96862745],\n",
       "         [0.52156863],\n",
       "         [0.01176471],\n",
       "         [0.14901961],\n",
       "         [0.86666667],\n",
       "         [0.99215686],\n",
       "         [0.80392157],\n",
       "         [0.01960784],\n",
       "         [0.        ],\n",
       "         [0.73333333],\n",
       "         [0.99215686]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [0.78823529],\n",
       "         [0.14901961],\n",
       "         [0.1372549 ],\n",
       "         [0.84313725],\n",
       "         [0.96470588],\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.97254902],\n",
       "         [0.99215686],\n",
       "         [0.98823529],\n",
       "         [0.98823529],\n",
       "         [0.61568627],\n",
       "         [0.08627451],\n",
       "         [0.00392157],\n",
       "         [0.01960784],\n",
       "         [0.63529412],\n",
       "         [0.01176471],\n",
       "         [0.01568627],\n",
       "         [0.70980392],\n",
       "         [0.8       ]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [0.99215686],\n",
       "         [0.83921569],\n",
       "         [0.86666667],\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.99607843],\n",
       "         [0.97647059],\n",
       "         [0.99215686],\n",
       "         [0.75686275],\n",
       "         [0.10196078],\n",
       "         [0.01568627],\n",
       "         [0.01568627],\n",
       "         [0.01568627],\n",
       "         [0.00784314],\n",
       "         [0.73333333],\n",
       "         [0.6745098 ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99215686],\n",
       "         [1.        ],\n",
       "         [0.06666667],\n",
       "         [0.07843137],\n",
       "         [0.04313725],\n",
       "         [0.03921569],\n",
       "         [0.73333333],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98039216],\n",
       "         [0.99607843],\n",
       "         [0.95294118],\n",
       "         [0.97647059],\n",
       "         [0.79607843],\n",
       "         [0.77254902],\n",
       "         [0.99607843],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.96078431],\n",
       "         [0.98823529],\n",
       "         [0.99607843],\n",
       "         [0.98431373],\n",
       "         [0.97647059],\n",
       "         [0.98823529],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.98823529],\n",
       "         [0.97647059],\n",
       "         [0.96470588],\n",
       "         [0.97254902],\n",
       "         [0.98431373],\n",
       "         [0.98039216],\n",
       "         [0.98823529],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [0.99215686],\n",
       "         [0.95686275],\n",
       "         [0.98039216],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [0.99607843],\n",
       "         [0.98823529],\n",
       "         [1.        ]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lol_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lol_prediction = model.predict(my_lol_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1581924e-07, 4.1368559e-10, 6.4555923e-07, 2.2491538e-05,\n",
       "        1.4397167e-12, 3.6010979e-15, 5.0695167e-11, 8.0478216e-08,\n",
       "        3.4654861e-12, 6.4896874e-08, 1.4367749e-06, 8.8046843e-05,\n",
       "        7.5111379e-06, 2.3038849e-01, 1.7430016e-06, 5.7561249e-09,\n",
       "        4.5668517e-07, 4.1635683e-08, 5.5010565e-09, 1.1502559e-11,\n",
       "        7.6300371e-01, 6.4844764e-03, 3.5521356e-07, 3.8272912e-08,\n",
       "        2.2634480e-07, 2.1373243e-10]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lol_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest element present in given array: 0.7630037\n"
     ]
    }
   ],
   "source": [
    "max = my_lol_prediction[0][0];    \n",
    "     \n",
    "#Loop through the array    \n",
    "for i in range(0, len(my_lol_prediction[0])):    \n",
    "    #Compare elements of array with max    \n",
    "   if(my_lol_prediction[0][i] > max):    \n",
    "       max = my_lol_prediction[0][i];    \n",
    "           \n",
    "print(\"Largest element present in given array: \" + str(max));   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(my_lol_prediction[0])):\n",
    "    if(my_lol_prediction[0][i] == max):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999418151907\n"
     ]
    }
   ],
   "source": [
    "mysum = 0\n",
    "for i in range(0, len(my_lol_prediction[0])):\n",
    "        mysum = mysum + my_lol_prediction[0][i]\n",
    "print(mysum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lol_prediction_2 = np_utils.to_categorical(my_lol_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lol_prediction_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:234 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-eaadab8cccde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_lol_prediction_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3357\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3277\u001b[0m           expand_composites=True)\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/nishanthkrishna/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:234 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "my_lol_prediction_3 = model.predict(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
